{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b9c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 02:54:04.747066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-26 02:54:05.296098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/usr/local/cuda-11.7/lib64${LD_LIBRARY_PATH:+:}\n",
      "2023-01-26 02:54:05.296261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/usr/local/cuda-11.7/lib64${LD_LIBRARY_PATH:+:}\n",
      "2023-01-26 02:54:05.296268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-26 02:54:05.888445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:54:05.912622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-26 02:54:05.912737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/cvlab/.local/lib/python3.10/site-packages/tqdm-4.64.1-py3.10.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "# MACHINE LEARNING LIBRARIES\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report,balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# OPTUNA\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "# CUSTOM LIBRARIES\n",
    "\n",
    "from video_gen import FrameGenerator\n",
    "\n",
    "from resnet183d import resnet3d\n",
    "from transformer import TransformerEncoder, pos_encoding,MultiHeadAttention,TubeletEmbedding,TransformerDecoder,Transformerfusion,Transformerfusion2\n",
    "from data import  random_flip, random_noise, one_hot,aug,combine_inputs\n",
    "from tools import CustomSchedule, CosineSchedule\n",
    "from tools import Logger,read_yaml\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import join,exists\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a4f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER CLASS \n",
    "class Trainer:\n",
    "    def __init__(self, config, logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.split = 1\n",
    "        self.fold = 0\n",
    "        self.trial = None\n",
    "        self.dataset=config['dataset']\n",
    "        self.features=config['features']\n",
    "        self.evaluation=config['evalutaion']\n",
    "        self.num_class=self.config[self.evaluation]['CLASSES']\n",
    "        if self.features=='skeleton':\n",
    "            self.pose=config[self.features]['pose']\n",
    "            \n",
    "            \n",
    "            self.dataset_dire_pose=join('../features/',self.dataset,self.features,self.pose,self.evaluation)\n",
    "\n",
    "            self.shape=(32,34)\n",
    "\n",
    "        elif self.features=='rgb':\n",
    "            self.backbone=self.config[self.features]['backbone']\n",
    "            self.dataset_dire_rgb=join('../features/',self.dataset,self.features,self.backbone,self.evaluation)\n",
    "            self.shape=(32,350,350,3)\n",
    "\n",
    "        else:\n",
    "            self.pose=config[self.features]['pose']\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.dataset_dire_pose=join('../features/',self.dataset,'skeleton',self.pose,self.evaluation)\n",
    "\n",
    "            self.shape_pose=(32,34)\n",
    "\n",
    "            self.backbone=self.config[self.features]['backbone']\n",
    "            self.dataset_dire_rgb=join('../features/',self.dataset,'rgb',self.backbone,self.evaluation,'crop')\n",
    "            self.shape_rgb=(32,1024)\n",
    "\n",
    "            self.arch=config[self.features]['arch']\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        self.result_dire=self.config['Result_dire']    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.bin_path = self.config['MODEL_DIR']\n",
    "        \n",
    "        self.model_size = self.config['MODEL_SIZE']\n",
    "        self.n_heads = self.config[self.model_size]['N_HEADS']\n",
    "        #self.n_heads = 256\n",
    "        self.n_layers = self.config[self.model_size]['N_LAYERS']\n",
    "        self.embed_dim = self.config[self.model_size]['EMBED_DIM']\n",
    "        self.dropout = self.config[self.model_size]['DROPOUT']\n",
    "        self.mlp_head_size = self.config[self.model_size]['MLP']\n",
    "        self.activation = tf.nn.gelu\n",
    "        self.d_model = 1 * self.n_heads\n",
    "        \n",
    "        self.d_ff = self.d_model * 2 \n",
    "\n",
    "\n",
    "\n",
    "    def build_act(self,transformer):\n",
    "        inputs = tf.keras.layers.Input(shape=self.shape)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # x=tf.keras.layers.LSTM(units=self.d_model,return_sequences=True)(inputs)\n",
    "        \n",
    "        # x=tf.keras.layers.LayerNormalization()(x)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        x = transformer(inputs,mask=None,training=True)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        x = tf.keras.layers.Lambda(lambda x: x[:,0,:])(x)\n",
    "        #x = tf.keras.layers.Dense(self.mlp_head_size)(x)\n",
    "        outputs = tf.keras.layers.Dense(self.num_class)(x)\n",
    "        return tf.keras.models.Model(inputs, outputs)\n",
    "        \n",
    "\n",
    "    def build_fusion(self,transformer_fusion):\n",
    "        input_pose = tf.keras.layers.Input(shape=self.shape_pose)\n",
    "        input_rgb=  tf.keras.layers.Input(shape=self.shape_rgb)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # x=tf.keras.layers.LSTM(units=self.d_model,return_sequences=True)(inputs)\n",
    "        \n",
    "        # x=tf.keras.layers.LayerNormalization()(x)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        # x = transformer_fusion([input_rgb,input_pose],mask=None,training=True)\n",
    "        x = transformer_fusion([input_pose,input_rgb],mask=None,training=True)\n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        x = tf.keras.layers.Lambda(lambda x: x[:,0,:])(x)\n",
    "        #x = tf.keras.layers.Dense(self.mlp_head_size)(x)\n",
    "        outputs = tf.keras.layers.Dense(self.num_class)(x)\n",
    "        return tf.keras.models.Model([input_pose,input_rgb], outputs)\n",
    "\n",
    "\n",
    "    def build_rgb_BERT(self,resnet):\n",
    "        \n",
    "\n",
    "        inputs=tf.keras.Input(shape=(32,350,350,3))\n",
    "\n",
    "        x=resnet(inputs)\n",
    "\n",
    "        # x = transformer(x,mask=None,training=True)\n",
    "\n",
    "\n",
    "        \n",
    "        # x = tf.keras.layers.Lambda(lambda x: x[:,0,:])(x)\n",
    "        # #x = tf.keras.layers.Dense(self.mlp_head_size)(x)\n",
    "        outputs = tf.keras.layers.Dense(self.num_class)(x)\n",
    "        return tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def get_model(self,trial_num):\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "        if self.features=='skeleton':\n",
    "            transformer = TransformerEncoder(d_model=self.d_model,dff=self.d_ff,num_heads=self.n_heads,rate=self.dropout,num_layers=self.n_layers)\n",
    "            self.model = self.build_act(transformer)\n",
    "            lr = CustomSchedule(self.d_model, \n",
    "                    warmup_steps=len(self.ds_train_pose)*self.config['N_EPOCHS']*self.config['WARMUP_PERC'],\n",
    "                    decay_step=len(self.ds_train_pose)*self.config['N_EPOCHS']*self.config['STEP_PERC'])\n",
    "        elif self.features=='rgb':\n",
    "            #transformer = TransformerEncoder(d_model=self.d_model,dff=self.d_ff,num_heads=self.n_heads,rate=self.dropout,num_layers=self.n_layers)\n",
    "            if self.backbone=='raw':\n",
    "                resnet=resnet3d(self.d_model)\n",
    "                \n",
    "                self.model=self.build_rgb_BERT(resnet)\n",
    "            else:\n",
    "                self.model = self.build_act(transformer)\n",
    "\n",
    "            lr = CustomSchedule(self.d_model, \n",
    "                warmup_steps=80*self.config['N_EPOCHS']*self.config['WARMUP_PERC'],\n",
    "                decay_step=80*self.config['N_EPOCHS']*self.config['STEP_PERC'])\n",
    "\n",
    "\n",
    "        else:\n",
    "            #transformer = TransformerEncoder(d_model=self.d_model,dff=self.d_ff,num_heads=self.n_heads,rate=self.dropout,num_layers=self.n_layers)\n",
    "            transformer_fusion=Transformerfusion2(d_model=self.d_model,dff=self.d_ff,num_heads=self.n_heads,rate=self.dropout,num_layers=self.n_layers)\n",
    "            self.model=self.build_fusion(transformer_fusion)\n",
    "\n",
    "\n",
    "        \n",
    "            lr = CustomSchedule(self.d_model, \n",
    "                warmup_steps=len(self.ds_train_fusion)*self.config['N_EPOCHS']*self.config['WARMUP_PERC'],\n",
    "                decay_step=len(self.ds_train_fusion)*self.config['N_EPOCHS']*self.config['STEP_PERC'])\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # lr = CustomSchedule(self.d_model, \n",
    "        #      warmup_steps=1190*self.config['N_EPOCHS']*self.config['WARMUP_PERC'],\n",
    "        #      decay_step=1190*self.config['N_EPOCHS']*self.config['STEP_PERC'])\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=self.config['WEIGHT_DECAY'])\n",
    "\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "                           metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",
    "                           )\n",
    "\n",
    "        self.name_model_bin = self.config['MODEL_NAME'] + '_' + self.config['MODEL_SIZE'] + '_' + str(self.split) + '_' + str(self.fold)\n",
    "        \n",
    "        if self.features=='skeleton':\n",
    "\n",
    "            self.new_bin_path=join(self.bin_path,self.dataset,self.features,self.pose,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "        elif self.features=='rgb':\n",
    "            self.new_bin_path=join(self.bin_path,self.dataset,self.features,self.backbone,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.new_bin_path=join(self.bin_path,self.dataset,self.features,self.arch,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        self.checkpointer = tf.keras.callbacks.ModelCheckpoint(self.new_bin_path+self.name_model_bin,\n",
    "                                                               monitor=\"val_accuracy\",\n",
    "                                                               save_best_only=True,\n",
    "                                                               save_weights_only=True)\n",
    "\n",
    "    def get_data_pose(self):\n",
    "\n",
    "        X_train=np.load(join(self.dataset_dire_pose,'train','features.npy'))\n",
    "        y_train=np.load(join(self.dataset_dire_pose,'train','labels.npy'))\n",
    "        X_test=np.load(join(self.dataset_dire_pose,'test','features.npy'))\n",
    "        y_test=np.load(join(self.dataset_dire_pose,'test','labels.npy'))\n",
    "        \n",
    "\n",
    "    \t\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=101,\n",
    "                                                          stratify=y_train)\n",
    "        \n",
    "        y_train=to_categorical(y_train,self.num_class)\n",
    "        y_val=to_categorical(y_val,self.num_class)\n",
    "        y_test=to_categorical(y_test,self.num_class)        \n",
    "        ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        # for _ in range(10):\n",
    "        #     ds_train.concatenate(ds_train.map(aug, num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "        # ds_train1 = ds_train1.map(random_noise, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        #ds_train = ds_train.concatenate(ds_train1)\n",
    "        ds_train = ds_train.cache()\n",
    "        #ds_train = ds_train.map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        # ds_train = ds_train.map(random_noise, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds_train = ds_train.shuffle(X_train.shape[0])\n",
    "        ds_train = ds_train.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_train_pose = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        ds_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        \n",
    "        # for _ in range(10):\n",
    "        #     ds_val.concatenate(ds_val.map(aug, num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "        \n",
    "        ds_val = ds_val.cache()\n",
    "        ds_val = ds_val.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_val_pose = ds_val.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        ds_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "        # ds_test = ds_test.map(lambda x,y : one_hot(x,y,self.config['CLASSES']), \n",
    "        #                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        \n",
    "        ds_test = ds_test.cache()\n",
    "\n",
    "        ds_test = ds_test.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_test_pose = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    def get_data_rgb(self):\n",
    "\n",
    "        # X_train=np.load(join(self.dataset_dire_rgb,'train','features.npy'))\n",
    "        # y_train=np.load(join(self.dataset_dire_rgb,'train','labels.npy'))\n",
    "        # X_test=np.load(join(self.dataset_dire_rgb,'test','features.npy'))\n",
    "        # y_test=np.load(join(self.dataset_dire_rgb,'test','labels.npy'))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        num_samples=len(glob(self.dataset_dire_rgb+'/**/*.npy'))\n",
    "       \n",
    "    \t\n",
    "        \n",
    "\n",
    "        batch_size=self.config['BATCH_SIZE']\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (3), dtype = tf.int16))\n",
    "        \n",
    "\n",
    "        ds=tf.data.Dataset.from_generator(FrameGenerator(rgb_path=self.dataset_dire_rgb,training=True),output_signature=output_signature)\n",
    "\n",
    "\n",
    "        self.train_len_rgb=np.math.ceil(0.70*num_samples)\n",
    "\n",
    "        val_len_rgb=np.math.ceil(0.10*num_samples)\n",
    "\n",
    "        test_len_rgb=num_samples-self.train_len_rgb-val_len_rgb\n",
    "\n",
    "\n",
    "        self.ds_train_rgb=ds.take(self.train_len_rgb)\n",
    "        self.ds_train_rgb=self.ds_train_rgb.cache('../cr/train/')\n",
    "        self.ds_train_rgb=self.ds_train_rgb.batch(batch_size)\n",
    "        self.ds_train_rgb=self.ds_train_rgb.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "        self.ds_val_rgb=ds.skip(self.train_len_rgb).take(val_len_rgb)\n",
    "        self.ds_val_rgb=self.ds_val_rgb.cache('../cr/val/')\n",
    "        self.ds_val_rgb=self.ds_val_rgb.batch(batch_size)\n",
    "        self.ds_val_rgb=self.ds_val_rgb.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "        self.ds_test_rgb=ds.skip(self.train_len_rgb+val_len_rgb).take(test_len_rgb)\n",
    "\n",
    "        self.ds_test_rgb=self.ds_test_rgb.cache('../cr/test/')\n",
    "        self.ds_test_rgb=self.ds_test_rgb.batch(batch_size)\n",
    "        self.ds_test_rgb=self.ds_test_rgb.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def get_data_fusion(self):\n",
    "        X_train_rgb=np.load(join(self.dataset_dire_rgb,'train','features.npy'))\n",
    "        print('X_train_rgb.shape: ',X_train_rgb.shape)\n",
    "        y_train_rgb=np.load(join(self.dataset_dire_rgb,'train','labels.npy'))\n",
    "        \n",
    "        X_test_rgb=np.load(join(self.dataset_dire_rgb,'test','features.npy'))\n",
    "        y_test=np.load(join(self.dataset_dire_rgb,'test','labels.npy'))\n",
    "\n",
    "        X_train_pose=np.load(join(self.dataset_dire_pose,'train','features.npy'))\n",
    "        y_train_pose=np.load(join(self.dataset_dire_pose,'train','labels.npy'))\n",
    "\n",
    "        print('X_train_pose.shape: ',X_train_pose.shape)\n",
    "        \n",
    "        X_test_pose=np.load(join(self.dataset_dire_pose,'test','features.npy'))\n",
    "        \n",
    "        X_train_pose, X_val_pose, y_train, y_val = train_test_split(X_train_pose, y_train_pose,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=101,\n",
    "                                                          stratify=y_train_pose)\n",
    "\n",
    "        X_train_rgb, X_val_rgb, _, _ = train_test_split(X_train_rgb, y_train_rgb,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=101,\n",
    "                                                          stratify=y_train_rgb)\n",
    "\n",
    "        y_train=to_categorical(y_train,self.num_class)\n",
    "        y_val=to_categorical(y_val,self.num_class)\n",
    "        y_test=to_categorical(y_test,self.num_class)   \n",
    "\n",
    "     \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        ds_train=tf.data.Dataset.from_tensor_slices((X_train_pose,X_train_rgb,y_train)).map(combine_inputs)\n",
    "        ds_train = ds_train.cache()\n",
    "        ds_train = ds_train.shuffle(X_train_pose.shape[0])\n",
    "        ds_train = ds_train.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_train_fusion = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "        ds_val=tf.data.Dataset.from_tensor_slices((X_val_pose,X_val_rgb,y_val)).map(combine_inputs)\n",
    "        ds_val = ds_val.cache()\n",
    "        ds_val = ds_val.shuffle(X_val_pose.shape[0])\n",
    "        ds_val = ds_val.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_val_fusion = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "        ds_test=tf.data.Dataset.from_tensor_slices((X_test_pose,X_test_rgb,y_test)).map(combine_inputs)\n",
    "        ds_test = ds_test.cache()\n",
    "        \n",
    "        ds_test = ds_test.batch(self.config['BATCH_SIZE'])\n",
    "        self.ds_test_fusion = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def get_random_hp(self):\n",
    "        self.config['RN_STD'] = self.trial.suggest_discrete_uniform(\"RN_STD\", 0.0, 0.05, 0.01)\n",
    "        self.config['WEIGHT_DECAY'] = self.trial.suggest_discrete_uniform(\"WD\", 1e-5, 1e-3, 1e-3)    \n",
    "        self.config['N_EPOCHS'] = int(self.trial.suggest_discrete_uniform(\"EPOCHS\",17,21,1))\n",
    "        \n",
    "        self.config['WARMUP_PERC'] = self.trial.suggest_discrete_uniform(\"WARMUP_PERC\", 0.2, 0.4, 0.1)\n",
    "        \n",
    "        self.logger.save_log('\\nRN_STD: {:.2e}'.format(self.config['RN_STD']))\n",
    "        self.logger.save_log('EPOCHS: {}'.format(self.config['N_EPOCHS']))\n",
    "        self.logger.save_log('WARMUP_PERC: {:.2e}'.format(self.config['WARMUP_PERC']))\n",
    "        self.logger.save_log('WEIGHT_DECAY: {:.2e}\\n'.format(self.config['WEIGHT_DECAY']))\n",
    "        \n",
    "    def do_training(self,trial_num=0):\n",
    "\n",
    "\n",
    "        if self.features=='skeleton':\n",
    "            self.get_data_pose()\n",
    "            self.get_model(trial_num)\n",
    "            history = self.model.fit(self.ds_train_pose,\n",
    "                epochs=self.config['N_EPOCHS'], initial_epoch=0,\n",
    "                validation_data=self.ds_val_pose,\n",
    "                callbacks=[self.checkpointer], verbose=self.config['VERBOSE'])\n",
    "\n",
    "            self.best_bin_path=join(self.bin_path,self.dataset,self.features,self.pose,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            self.model.load_weights(self.best_bin_path+self.name_model_bin) \n",
    "            \n",
    "                \n",
    "            _, accuracy_test = self.model.evaluate(self.ds_test_pose)\n",
    "\n",
    "            \n",
    "            \n",
    "            X, y_true = tuple(zip(*self.ds_test))\n",
    "            y_pred = np.argmax(tf.nn.softmax(self.model.predict(tf.concat(X, axis=0)), axis=-1),axis=1)\n",
    "            y_true=np.argmax(y_true,axis=0)\n",
    "            \n",
    "            \n",
    "            y_true=np.load(join(self.dataset_dire_pose,'test','labels.npy'))\n",
    "            y_pred=np.argmax(self.model.predict(self.ds_test_pose),axis=-1)\n",
    "            \n",
    "            class_report=classification_report(y_true,y_pred)\n",
    "\n",
    "\n",
    "            balanced_accuracy = sklearn.metrics.balanced_accuracy_score(y_true,y_pred)\n",
    "\n",
    "            text = f\"{self.config['MODEL_SIZE']}:  Accuracy Test: {accuracy_test} <> Balanced Accuracy: {balanced_accuracy}\\n\"\n",
    "\n",
    "            \n",
    "            \n",
    "            text1 = 'Classification Report \\n{}'.format(class_report)\n",
    "            \n",
    "            self.logger.save_log(text)\n",
    "            self.logger.save_log(text1)\n",
    "            return accuracy_test, balanced_accuracy,history.history\n",
    "\n",
    "\n",
    "            #print('len :',len(self.ds_train))\n",
    "        elif self.features=='rgb':\n",
    "            if self.backbone=='raw':\n",
    "                self.get_data_rgb()\n",
    "\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                self.get_data_rgb()\n",
    "\n",
    "            \n",
    "\n",
    "            self.get_model(trial_num)\n",
    "\n",
    "            history = self.model.fit(self.ds_train_rgb,\n",
    "                epochs=self.config['N_EPOCHS'], initial_epoch=0,\n",
    "                validation_data=self.ds_val_rgb,\n",
    "                callbacks=[self.checkpointer], verbose=self.config['VERBOSE'])\n",
    "\n",
    "            self.best_bin_path=join(self.bin_path,self.dataset,self.features,self.backbone,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            self.model.load_weights(self.best_bin_path+self.name_model_bin) \n",
    "            _, accuracy_test = self.model.evaluate(self.ds_test_rgb)\n",
    "            X, y_true = tuple(zip(*self.ds_test_rgb))\n",
    "            y_true=tf.concat(y_true, axis=0)\n",
    "            y_pred = np.argmax(tf.nn.softmax(self.model.predict(tf.concat(X, axis=0)), axis=-1),axis=1)\n",
    "            y_true=np.argmax(y_true,axis=1)\n",
    "            print('Shape: ',y_true.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            class_report=classification_report(y_true,y_pred)\n",
    "\n",
    "\n",
    "            balanced_accuracy = sklearn.metrics.balanced_accuracy_score(y_true,y_pred)\n",
    "\n",
    "            text = f\"{self.config['MODEL_SIZE']}:  Accuracy Test: {accuracy_test} <> Balanced Accuracy: {balanced_accuracy}\\n\"\n",
    "\n",
    "            \n",
    "            \n",
    "            text1 = 'Classification Report \\n{}'.format(class_report)\n",
    "            \n",
    "            self.logger.save_log(text)\n",
    "            self.logger.save_log(text1)\n",
    "            return accuracy_test, balanced_accuracy,history.history\n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            self.get_data_fusion()\n",
    "\n",
    "            self.get_model(trial_num)\n",
    "\n",
    "            history = self.model.fit(self.ds_train_fusion,\n",
    "                epochs=self.config['N_EPOCHS'], initial_epoch=0,\n",
    "                validation_data=self.ds_val_fusion,\n",
    "                callbacks=[self.checkpointer], verbose=self.config['VERBOSE'])\n",
    "\n",
    "            self.best_bin_path=join(self.bin_path,self.dataset,self.features,self.arch,self.evaluation,self.config['MODEL_SIZE'],'{:04d}/'.format(trial_num))\n",
    "\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            self.model.load_weights(self.best_bin_path+self.name_model_bin) \n",
    "            \n",
    "                \n",
    "            _, accuracy_test = self.model.evaluate(self.ds_test_fusion)\n",
    "\n",
    "            y_true=np.load(join(self.dataset_dire_rgb,'test','labels.npy'))\n",
    "            y_pred=np.argmax(self.model.predict(self.ds_test_fusion),axis=-1)\n",
    "            # #print('y.shape :', y_pred.shape)\n",
    "\n",
    "            \n",
    "            class_report=classification_report(y_true,y_pred)\n",
    "\n",
    "\n",
    "            balanced_accuracy = sklearn.metrics.balanced_accuracy_score(y_true,y_pred)\n",
    "\n",
    "            text = f\"{self.config['MODEL_SIZE']}:  Accuracy Test: {accuracy_test} <> Balanced Accuracy: {balanced_accuracy}\\n\"\n",
    "            \n",
    "            text1 = 'Classification Report \\n{}'.format(class_report)\n",
    "            \n",
    "            self.logger.save_log(text)\n",
    "            self.logger.save_log(text1)\n",
    "            return accuracy_test,balanced_accuracy,history.history\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def start_training(self, trial):\n",
    "            \n",
    "        \n",
    "        acc,_,_ = self.do_training()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89325f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "config = read_yaml('config.yaml')\n",
    "logger = Logger(config['LOG_DIR']+now.strftime(\"%y%m%d%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8680c304",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e2818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "85db18ce2fe3f95ddef0eb50df32b5323cfb3f595459ab1005c6551e46d04245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
