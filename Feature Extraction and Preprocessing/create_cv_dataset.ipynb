{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os \n",
    "from os.path import join,exists,basename\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths={'full_dataset':join('datasets_features','smarthome','new_pose','Full'),\n",
    "'cv1_train':join('datasets_features','smarthome','new_pose','CV1','train'),\n",
    "'cv1_test':join('datasets_features','smarthome','new_pose','CV1','test'),\n",
    "'cv2_train':join('datasets_features','smarthome','new_pose','CV2','train'),\n",
    "'cv2_test':join('datasets_features','smarthome','new_pose','CV2','test')}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For old_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths={'full_dataset':join('datasets_features','smarthome','old_pose','Full'),\n",
    "# 'cv1_train':join('datasets_features','smarthome','old_pose','CV1','train'),\n",
    "# 'cv1_test':join('datasets_features','smarthome','old_pose','CV1','test'),\n",
    "# 'cv2_train':join('datasets_features','smarthome','old_pose','CV2','train'),\n",
    "# 'cv2_test':join('datasets_features','smarthome','old_pose','CV2','test')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:full_dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "for key,value in paths.items():\n",
    "    if not exists(value):\n",
    "        os.makedirs(value)\n",
    "    else:\n",
    "        print('Path:{} already exists.'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames=os.listdir(paths['full_dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subclassnames=['Cutbread', 'Drink.Frombottle', 'Drink.Fromcan', 'Drink.Fromcup', 'Drink.Fromglass', 'Eat.Attable', 'Eat.Snack', 'Enter', 'Getup', 'Leave', \n",
    "'Pour.Frombottle', 'Pour.Fromcan', 'Readbook', 'Sitdown', 'Takepills', 'Uselaptop', 'Usetablet','Usetelephone','Walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train and test id\n",
    "cv1_trainid=[1]\n",
    "cv2_trainid=[1,3,4,6,7]\n",
    "test_id=[2]\n",
    "valid_id=[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create different train dataset for cv1\n",
    "for className in Subclassnames:\n",
    "    json_dires=glob(join(paths['full_dataset'],className)+'/*.json')\n",
    "    for json_dire in json_dires:\n",
    "        baseName=basename(json_dire)\n",
    "        cam_id=int(json_dire.split('_')[-2][1:])\n",
    "        \n",
    "        if cam_id in cv1_trainid:\n",
    "            new_dire=join(paths['cv1_train'],className)\n",
    "\n",
    "            if not exists(new_dire):\n",
    "                os.makedirs(new_dire)\n",
    "\n",
    "            target_path=join(new_dire,basename(json_dire))\n",
    "            shutil.copy(json_dire,target_path)\n",
    "            \n",
    "\n",
    "        elif cam_id in test_id:\n",
    "            new_dire=join(paths['cv1_test'],className)\n",
    "\n",
    "            \n",
    "\n",
    "            if not exists(new_dire):\n",
    "                os.makedirs(new_dire)\n",
    "\n",
    "            target_path=join(new_dire,basename(json_dire))\n",
    "            shutil.copy(json_dire,target_path)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create different train dataset for cv2\n",
    "for className in Subclassnames:\n",
    "    json_dires=glob(join(paths['full_dataset'],className)+'/*.json')\n",
    "    for json_dire in json_dires:\n",
    "        baseName=basename(json_dire)\n",
    "        cam_id=int(json_dire.split('_')[-2][1:])\n",
    "        \n",
    "        if cam_id in cv2_trainid:\n",
    "            new_dire=join(paths['cv2_train'],className)\n",
    "\n",
    "            if not exists(new_dire):\n",
    "                os.makedirs(new_dire)\n",
    "\n",
    "            target_path=join(new_dire,basename(json_dire))\n",
    "            shutil.copy(json_dire,target_path)\n",
    "            \n",
    "\n",
    "        elif cam_id in test_id:\n",
    "            new_dire=join(paths['cv2_test'],className)\n",
    "\n",
    "            \n",
    "\n",
    "            if not exists(new_dire):\n",
    "                os.makedirs(new_dire)\n",
    "\n",
    "            target_path=join(new_dire,basename(json_dire))\n",
    "            shutil.copy(json_dire,target_path)\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85db18ce2fe3f95ddef0eb50df32b5323cfb3f595459ab1005c6551e46d04245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
